# 30-Day AI Engineer Roadmap (From Python Basics ‚Üí Mini-GPT)

**Goal:**  
Understand how ChatGPT-like models work from first principles and build a **tiny GPT model** in 30 days.

**Target Audience:**  
Beginner with basic Python knowledge (loops, functions, variables).

**Daily Time Commitment:**  
‚è± 2‚Äì3 hours/day  
üö´ No skipping days

---

## üìÖ Roadmap Overview

- **Week 1:** Python + Math Foundations  
- **Week 2:** Machine Learning & Neural Networks  
- **Week 3:** Deep Learning & Transformers  
- **Week 4:** Training, Scaling & AI Systems Reality  

---

## üß† Learning Philosophy

- Learn **why**, not just **how**
- Build things **from scratch** before using libraries
- Focus on **understanding**, not memorization
- Write notes & code every day

---


---

## üü¶ WEEK 1 Python & Math Foundations

### Day 1
- Python basics revision
- Functions, lists, dicts
- Implement dot product manually

### Day 2
- NumPy arrays & shapes
- Vector & matrix operations

### Day 3
- Linear algebra basics
- Cosine similarity implementation

### Day 4
- Probability basics (mean, variance, std)
- Manual + NumPy calculations

### Day 5
- Gradient intuition
- Loss curves & optimization idea

### Day 6
- Linear Regression from scratch (NumPy only)

### Day 7
- Review & refactor
- Write summary notes

---

## üü¶ WEEK 2 Machine Learning & Neural Networks

### Day 8
- ML fundamentals
- Train/test split, overfitting

### Day 9
- Logistic Regression from scratch
- Sigmoid & classification loss

### Day 10
- Neural Network basics
- Neurons, weights, activations

### Day 11
- Build a 1-layer NN (NumPy)

### Day 12
- Backpropagation intuition
- Chain rule in practice

### Day 13
- PyTorch basics
- Tensors & autograd

### Day 14
- Train a neural network with PyTorch

---

## üü¶ WEEK 3 Deep Learning & Transformers

### Day 15
- Word embeddings
- Vector lookup tables

### Day 16
- Attention mechanism
- Query, Key, Value

### Day 17
- Self-Attention
- Visualize attention weights

### Day 18
- Transformer block
- Attention + Feedforward

### Day 19
- Positional Encoding
- Sinusoidal encoding

### Day 20
- GPT architecture
- Causal masking & next-token prediction

### Day 21
- Build a tiny GPT (character-level)

---

## üü¶ WEEK 4 Training, Scaling & Reality

### Day 22
- Training loops
- Batching & epochs

### Day 23
- GPU & CUDA basics (conceptual)
- Why training is expensive

### Day 24
- Model evaluation
- Why models hallucinate

### Day 25
- Tokenization
- BPE vs character-level

### Day 26
- Pre-training vs fine-tuning

### Day 27
- Safety & alignment basics

### Day 28
- Model serving basics
- Inference, latency, batching

### Day 29
- Code cleanup
- Documentation & diagrams

### Day 30
üéØ **Outcome**
- Understand how ChatGPT works
- Build and explain a mini-GPT
- Ready for LLM engineering or fine-tuning work

---

## üöÄ Final Outcome

After 30 days, you will:
- Understand transformers deeply
- Know why scale matters
- Be able to build & explain GPT-style models
- Be ready for real AI engineering paths

---

## ‚ö†Ô∏è Reality Check

- You will NOT recreate ChatGPT
- You WILL understand how it works
- You WILL be ahead of most beginners

---

## ‚ú® Next Steps

Choose one:
1. LLM App Engineer (RAG, agents, AI products)
2. ML Engineer (training, pipelines, infra)

---

**Start Date:** 30/12/2025 
**End Date:** 28/1/2026 

Let‚Äôs build real intelligence step by step.
