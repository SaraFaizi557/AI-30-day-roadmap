# 30-Day AI Engineer Roadmap (From Python Basics â†’ Mini-GPT)

**Goal:**  
Understand how ChatGPT-like models work from first principles and build a **tiny GPT model** in 30 days.

**Target Audience:**  
Beginner with basic Python knowledge (loops, functions, variables).

**Daily Time Commitment:**  
â± 2â€“3 hours/day  
ğŸš« No skipping days

---

## ğŸ“… Roadmap Overview

- **Week 1:** Python + Math Foundations  
- **Week 2:** Machine Learning & Neural Networks  
- **Week 3:** Deep Learning & Transformers  
- **Week 4:** Training, Scaling & AI Systems Reality  

---

## ğŸ§  Learning Philosophy

- Learn **why**, not just **how**
- Build things **from scratch** before using libraries
- Focus on **understanding**, not memorization
- Write notes & code every day

---


---

## ğŸŸ¦ WEEK 1 â€” Python & Math Foundations

### Day 1
- Python basics revision
- Functions, lists, dicts
- Implement dot product manually

### Day 2
- NumPy arrays & shapes
- Vector & matrix operations

### Day 3
- Linear algebra basics
- Cosine similarity implementation

### Day 4
- Probability basics (mean, variance, std)
- Manual + NumPy calculations

### Day 5
- Gradient intuition
- Loss curves & optimization idea

### Day 6
- Linear Regression from scratch (NumPy only)

### Day 7
- Review & refactor
- Write summary notes

---

## ğŸŸ¦ WEEK 2 â€” Machine Learning & Neural Networks

### Day 8
- ML fundamentals
- Train/test split, overfitting

### Day 9
- Logistic Regression from scratch
- Sigmoid & classification loss

### Day 10
- Neural Network basics
- Neurons, weights, activations

### Day 11
- Build a 1-layer NN (NumPy)

### Day 12
- Backpropagation intuition
- Chain rule in practice

### Day 13
- PyTorch basics
- Tensors & autograd

### Day 14
- Train a neural network with PyTorch

---

## ğŸŸ¦ WEEK 3 â€” Deep Learning & Transformers

### Day 15
- Word embeddings
- Vector lookup tables

### Day 16
- Attention mechanism
- Query, Key, Value

### Day 17
- Self-Attention
- Visualize attention weights

### Day 18
- Transformer block
- Attention + Feedforward

### Day 19
- Positional Encoding
- Sinusoidal encoding

### Day 20
- GPT architecture
- Causal masking & next-token prediction

### Day 21
- Build a tiny GPT (character-level)

---

## ğŸŸ¦ WEEK 4 â€” Training, Scaling & Reality

### Day 22
- Training loops
- Batching & epochs

### Day 23
- GPU & CUDA basics (conceptual)
- Why training is expensive

### Day 24
- Model evaluation
- Why models hallucinate

### Day 25
- Tokenization
- BPE vs character-level

### Day 26
- Pre-training vs fine-tuning

### Day 27
- Safety & alignment basics

### Day 28
- Model serving basics
- Inference, latency, batching

### Day 29
- Code cleanup
- Documentation & diagrams

### Day 30
ğŸ¯ **Outcome**
- Understand how ChatGPT works
- Build and explain a mini-GPT
- Ready for LLM engineering or fine-tuning work

---

## ğŸš€ Final Outcome

After 30 days, you will:
- Understand transformers deeply
- Know why scale matters
- Be able to build & explain GPT-style models
- Be ready for real AI engineering paths

---

## âš ï¸ Reality Check

- You will NOT recreate ChatGPT
- You WILL understand how it works
- You WILL be ahead of most beginners

---

## âœ¨ Next Steps

Choose one:
1. LLM App Engineer (RAG, agents, AI products)
2. ML Engineer (training, pipelines, infra)

---

**Start Date:** __________  
**End Date:** __________  

Letâ€™s build real intelligence â€” step by step.